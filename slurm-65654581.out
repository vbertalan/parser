


huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
/project/6023391/vberta/Parser/parser/.venv/lib/python3.8/site-packages/transformers/data/datasets/language_modeling.py:121: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py
  warnings.warn(
Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.
Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.
Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.
/project/6023391/vberta/Parser/parser/.venv/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 15710
  Num Epochs = 1
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 246
  Number of trainable parameters = 83622688
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: Currently logged in as: vbertalan (vbertalan88). Use `wandb login --relogin` to force relogin
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
wandb: wandb version 0.15.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.1
wandb: Run data is saved locally in /project/6023391/vberta/Parser-CC/parser/wandb/run-20230421_132413-hqzmgw5t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-wind-7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vbertalan88/huggingface
wandb: üöÄ View run at https://wandb.ai/vbertalan88/huggingface/runs/hqzmgw5t
O numero de parametros e 83622688
  0%|          | 0/246 [00:00<?, ?it/s]You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/246 [00:02<10:33,  2.58s/it]  1%|          | 2/246 [00:02<05:11,  1.28s/it]  1%|          | 3/246 [00:03<03:30,  1.16it/s]  2%|‚ñè         | 4/246 [00:03<02:43,  1.48it/s]  2%|‚ñè         | 5/246 [00:04<02:16,  1.77it/s]  2%|‚ñè         | 6/246 [00:04<02:00,  1.99it/s]  3%|‚ñé         | 7/246 [00:05<02:11,  1.81it/s]  3%|‚ñé         | 8/246 [00:05<01:57,  2.02it/s]  4%|‚ñé         | 9/246 [00:05<01:47,  2.20it/s]  4%|‚ñç         | 10/246 [00:06<01:50,  2.14it/s]  4%|‚ñç         | 11/246 [00:06<01:43,  2.27it/s]  5%|‚ñç         | 12/246 [00:07<01:39,  2.36it/s]  5%|‚ñå         | 13/246 [00:07<01:35,  2.44it/s]  6%|‚ñå         | 14/246 [00:08<01:47,  2.15it/s]  6%|‚ñå         | 15/246 [00:09<02:22,  1.62it/s]  7%|‚ñã         | 16/246 [00:09<02:17,  1.67it/s]  7%|‚ñã         | 17/246 [00:09<02:01,  1.88it/s]  7%|‚ñã         | 18/246 [00:10<01:49,  2.08it/s]  8%|‚ñä         | 19/246 [00:11<02:03,  1.84it/s]  8%|‚ñä         | 20/246 [00:11<02:17,  1.65it/s]  9%|‚ñä         | 21/246 [00:12<02:00,  1.87it/s]  9%|‚ñâ         | 22/246 [00:12<01:49,  2.05it/s]  9%|‚ñâ         | 23/246 [00:12<01:41,  2.20it/s] 10%|‚ñâ         | 24/246 [00:13<01:35,  2.33it/s] 10%|‚ñà         | 25/246 [00:13<01:31,  2.41it/s] 11%|‚ñà         | 26/246 [00:14<01:28,  2.48it/s] 11%|‚ñà         | 27/246 [00:14<01:26,  2.55it/s] 11%|‚ñà‚ñè        | 28/246 [00:14<01:24,  2.58it/s] 12%|‚ñà‚ñè        | 29/246 [00:15<01:22,  2.62it/s] 12%|‚ñà‚ñè        | 30/246 [00:15<01:21,  2.64it/s] 13%|‚ñà‚ñé        | 31/246 [00:16<01:42,  2.10it/s] 13%|‚ñà‚ñé        | 32/246 [00:16<01:36,  2.23it/s] 13%|‚ñà‚ñé        | 33/246 [00:16<01:30,  2.34it/s] 14%|‚ñà‚ñç        | 34/246 [00:17<01:27,  2.43it/s] 14%|‚ñà‚ñç        | 35/246 [00:17<01:24,  2.50it/s] 15%|‚ñà‚ñç        | 36/246 [00:18<01:22,  2.55it/s] 15%|‚ñà‚ñå        | 37/246 [00:18<01:20,  2.58it/s] 15%|‚ñà‚ñå        | 38/246 [00:18<01:19,  2.61it/s] 16%|‚ñà‚ñå        | 39/246 [00:19<01:18,  2.64it/s] 16%|‚ñà‚ñã        | 40/246 [00:19<01:17,  2.65it/s] 17%|‚ñà‚ñã        | 41/246 [00:19<01:17,  2.66it/s] 17%|‚ñà‚ñã        | 42/246 [00:20<01:16,  2.66it/s] 17%|‚ñà‚ñã        | 43/246 [00:20<01:16,  2.67it/s] 18%|‚ñà‚ñä        | 44/246 [00:21<01:17,  2.60it/s] 18%|‚ñà‚ñä        | 45/246 [00:21<01:16,  2.62it/s] 19%|‚ñà‚ñä        | 46/246 [00:21<01:15,  2.65it/s] 19%|‚ñà‚ñâ        | 47/246 [00:22<01:37,  2.04it/s] 20%|‚ñà‚ñâ        | 48/246 [00:23<01:30,  2.19it/s] 20%|‚ñà‚ñâ        | 49/246 [00:23<01:24,  2.32it/s] 20%|‚ñà‚ñà        | 50/246 [00:23<01:21,  2.42it/s] 21%|‚ñà‚ñà        | 51/246 [00:24<01:21,  2.38it/s] 21%|‚ñà‚ñà        | 52/246 [00:24<01:18,  2.49it/s] 22%|‚ñà‚ñà‚ñè       | 53/246 [00:24<01:16,  2.54it/s] 22%|‚ñà‚ñà‚ñè       | 54/246 [00:25<01:14,  2.58it/s] 22%|‚ñà‚ñà‚ñè       | 55/246 [00:25<01:12,  2.62it/s] 23%|‚ñà‚ñà‚ñé       | 56/246 [00:26<01:12,  2.61it/s] 23%|‚ñà‚ñà‚ñé       | 57/246 [00:26<01:13,  2.57it/s] 24%|‚ñà‚ñà‚ñé       | 58/246 [00:26<01:11,  2.62it/s] 24%|‚ñà‚ñà‚ñç       | 59/246 [00:27<01:24,  2.22it/s] 24%|‚ñà‚ñà‚ñç       | 60/246 [00:27<01:19,  2.33it/s] 25%|‚ñà‚ñà‚ñç       | 61/246 [00:28<01:18,  2.37it/s] 25%|‚ñà‚ñà‚ñå       | 62/246 [00:28<01:15,  2.44it/s] 26%|‚ñà‚ñà‚ñå       | 63/246 [00:29<01:16,  2.40it/s] 26%|‚ñà‚ñà‚ñå       | 64/246 [00:29<01:13,  2.47it/s] 26%|‚ñà‚ñà‚ñã       | 65/246 [00:29<01:11,  2.55it/s] 27%|‚ñà‚ñà‚ñã       | 66/246 [00:30<01:13,  2.44it/s] 27%|‚ñà‚ñà‚ñã       | 67/246 [00:30<01:31,  1.95it/s] 28%|‚ñà‚ñà‚ñä       | 68/246 [00:31<01:23,  2.14it/s] 28%|‚ñà‚ñà‚ñä       | 69/246 [00:31<01:17,  2.28it/s] 28%|‚ñà‚ñà‚ñä       | 70/246 [00:32<01:13,  2.39it/s] 29%|‚ñà‚ñà‚ñâ       | 71/246 [00:32<01:10,  2.48it/s] 29%|‚ñà‚ñà‚ñâ       | 72/246 [00:32<01:08,  2.55it/s] 30%|‚ñà‚ñà‚ñâ       | 73/246 [00:35<03:22,  1.17s/it] 30%|‚ñà‚ñà‚ñà       | 74/246 [00:36<02:56,  1.02s/it] 30%|‚ñà‚ñà‚ñà       | 75/246 [00:36<02:21,  1.21it/s] 31%|‚ñà‚ñà‚ñà       | 76/246 [00:37<01:57,  1.45it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 77/246 [00:37<01:40,  1.69it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 78/246 [00:37<01:28,  1.90it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 79/246 [00:38<01:20,  2.08it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 80/246 [00:38<01:14,  2.23it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 81/246 [00:39<01:10,  2.36it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 82/246 [00:39<01:16,  2.14it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 83/246 [00:39<01:11,  2.29it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 84/246 [00:40<01:07,  2.39it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 85/246 [00:40<01:05,  2.47it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 86/246 [00:41<01:03,  2.51it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 87/246 [00:41<01:01,  2.57it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 88/246 [00:41<01:00,  2.60it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 89/246 [00:42<00:59,  2.62it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 90/246 [00:42<00:59,  2.64it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 91/246 [00:42<00:58,  2.65it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 92/246 [00:43<00:58,  2.64it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 93/246 [00:43<00:57,  2.65it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 94/246 [00:44<00:57,  2.66it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 95/246 [00:44<00:56,  2.66it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 96/246 [00:44<00:56,  2.66it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 97/246 [00:45<00:58,  2.56it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 98/246 [00:45<00:56,  2.60it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 99/246 [00:46<00:55,  2.64it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 100/246 [00:46<00:55,  2.64it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 101/246 [00:46<00:54,  2.65it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 102/246 [00:47<00:54,  2.66it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 103/246 [00:47<00:53,  2.68it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 104/246 [00:48<00:59,  2.37it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 105/246 [00:48<00:57,  2.45it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 106/246 [00:48<00:55,  2.53it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 107/246 [00:49<00:53,  2.59it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 108/246 [00:49<01:08,  2.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 109/246 [00:50<01:03,  2.17it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 110/246 [00:50<00:58,  2.31it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 111/246 [00:51<00:55,  2.43it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 112/246 [00:51<00:53,  2.50it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 113/246 [00:51<00:52,  2.55it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 114/246 [00:52<00:53,  2.47it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 115/246 [00:52<00:52,  2.51it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 116/246 [00:52<00:51,  2.54it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 117/246 [00:53<00:49,  2.58it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 118/246 [00:53<00:49,  2.59it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 119/246 [00:54<00:53,  2.38it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 120/246 [00:54<00:51,  2.46it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 121/246 [00:54<00:49,  2.52it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 122/246 [00:55<00:48,  2.58it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 123/246 [00:55<00:47,  2.61it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 124/246 [00:56<00:46,  2.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 125/246 [00:56<00:46,  2.63it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 126/246 [00:56<00:45,  2.66it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 127/246 [00:57<00:58,  2.04it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 128/246 [00:58<01:02,  1.89it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 129/246 [00:58<00:56,  2.08it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 130/246 [00:59<01:02,  1.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 131/246 [00:59<00:56,  2.02it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 132/246 [01:00<00:52,  2.18it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 133/246 [01:00<00:48,  2.31it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 134/246 [01:00<00:46,  2.42it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 135/246 [01:01<00:45,  2.45it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 136/246 [01:01<00:43,  2.52it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 137/246 [01:01<00:42,  2.58it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 138/246 [01:02<00:41,  2.62it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 139/246 [01:02<00:40,  2.65it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 140/246 [01:03<00:39,  2.67it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 141/246 [01:03<00:39,  2.67it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 142/246 [01:03<00:38,  2.69it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 143/246 [01:04<00:45,  2.28it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 144/246 [01:04<00:42,  2.40it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 145/246 [01:05<00:45,  2.20it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 146/246 [01:05<00:46,  2.14it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 147/246 [01:06<00:47,  2.09it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 148/246 [01:06<00:43,  2.24it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 149/246 [01:06<00:41,  2.35it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 150/246 [01:08<01:03,  1.51it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 151/246 [01:08<00:58,  1.63it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 152/246 [01:09<00:51,  1.84it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 153/246 [01:09<00:45,  2.03it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 154/246 [01:09<00:41,  2.20it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 155/246 [01:10<00:40,  2.23it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 156/246 [01:10<00:38,  2.36it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 157/246 [01:10<00:36,  2.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 158/246 [01:11<00:34,  2.54it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 159/246 [01:11<00:36,  2.36it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 160/246 [01:12<00:35,  2.45it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 161/246 [01:12<00:33,  2.51it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 162/246 [01:12<00:32,  2.56it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 163/246 [01:13<00:32,  2.59it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 164/246 [01:13<00:31,  2.62it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 165/246 [01:14<00:30,  2.63it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 166/246 [01:14<00:30,  2.64it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 167/246 [01:14<00:29,  2.66it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 168/246 [01:15<00:29,  2.68it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 169/246 [01:15<00:28,  2.67it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 170/246 [01:15<00:28,  2.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 171/246 [01:16<00:31,  2.34it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 172/246 [01:16<00:31,  2.34it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 173/246 [01:17<00:30,  2.43it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 174/246 [01:17<00:28,  2.51it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 175/246 [01:18<00:27,  2.55it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 176/246 [01:18<00:35,  1.99it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 177/246 [01:19<00:31,  2.17it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 178/246 [01:19<00:29,  2.30it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 179/246 [01:19<00:27,  2.40it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 180/246 [01:20<00:26,  2.47it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 181/246 [01:20<00:25,  2.54it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 182/246 [01:21<00:29,  2.21it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 183/246 [01:21<00:27,  2.33it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 184/246 [01:22<00:25,  2.42it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 185/246 [01:22<00:24,  2.49it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 186/246 [01:22<00:27,  2.16it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 187/246 [01:23<00:29,  2.00it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 188/246 [01:23<00:26,  2.16it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 189/246 [01:24<00:25,  2.21it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 190/246 [01:24<00:23,  2.33it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 191/246 [01:25<00:22,  2.44it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 192/246 [01:25<00:21,  2.50it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 193/246 [01:25<00:20,  2.57it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 194/246 [01:26<00:20,  2.60it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 195/246 [01:26<00:19,  2.61it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 196/246 [01:27<00:20,  2.42it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 197/246 [01:27<00:19,  2.49it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 198/246 [01:27<00:18,  2.55it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 199/246 [01:28<00:18,  2.60it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 200/246 [01:28<00:17,  2.62it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 201/246 [01:28<00:17,  2.64it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 202/246 [01:29<00:16,  2.65it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 203/246 [01:30<00:20,  2.08it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 204/246 [01:30<00:18,  2.23it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 205/246 [01:30<00:19,  2.06it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 206/246 [01:31<00:19,  2.07it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 207/246 [01:31<00:17,  2.23it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 208/246 [01:32<00:16,  2.31it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 209/246 [01:32<00:15,  2.41it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 210/246 [01:32<00:14,  2.50it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 211/246 [01:33<00:13,  2.51it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 212/246 [01:33<00:13,  2.58it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 213/246 [01:34<00:12,  2.62it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 214/246 [01:34<00:12,  2.52it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 215/246 [01:34<00:12,  2.44it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 216/246 [01:35<00:11,  2.50it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 217/246 [01:35<00:11,  2.55it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 218/246 [01:36<00:11,  2.37it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 219/246 [01:36<00:10,  2.47it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 220/246 [01:36<00:10,  2.53it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 221/246 [01:37<00:09,  2.59it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 222/246 [01:37<00:09,  2.61it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 223/246 [01:38<00:08,  2.62it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 224/246 [01:38<00:08,  2.64it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 225/246 [01:38<00:07,  2.65it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 226/246 [01:39<00:08,  2.48it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 227/246 [01:40<00:09,  1.99it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 228/246 [01:40<00:08,  2.16it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 229/246 [01:41<00:09,  1.86it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 230/246 [01:41<00:07,  2.04it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 231/246 [01:41<00:07,  2.12it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 232/246 [01:42<00:06,  2.27it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 233/246 [01:42<00:06,  2.10it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 234/246 [01:43<00:05,  2.26it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 235/246 [01:43<00:04,  2.32it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 236/246 [01:43<00:04,  2.44it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 237/246 [01:44<00:03,  2.52it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 238/246 [01:44<00:03,  2.56it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 239/246 [01:45<00:02,  2.59it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 240/246 [01:45<00:02,  2.24it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 241/246 [01:46<00:02,  2.36it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 242/246 [01:46<00:01,  2.45it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 243/246 [01:46<00:01,  2.53it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 244/246 [01:47<00:00,  2.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 245/246 [01:47<00:00,  2.17it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 246/246 [01:48<00:00,  2.58it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 246/246 [01:48<00:00,  2.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 246/246 [01:48<00:00,  2.28it/s]
Saving model checkpoint to ./Ciena-Mini-Transformer
Configuration saved in ./Ciena-Mini-Transformer/config.json
Model weights saved in ./Ciena-Mini-Transformer/pytorch_model.bin
{'train_runtime': 116.1013, 'train_samples_per_second': 135.313, 'train_steps_per_second': 2.119, 'train_loss': 3.613180269070757, 'epoch': 1.0}
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                    train/epoch ‚ñÅ
wandb:              train/global_step ‚ñÅ
wandb:               train/total_flos ‚ñÅ
wandb:               train/train_loss ‚ñÅ
wandb:            train/train_runtime ‚ñÅ
wandb: train/train_samples_per_second ‚ñÅ
wandb:   train/train_steps_per_second ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    train/epoch 1.0
wandb:              train/global_step 246
wandb:               train/total_flos 270776949880320.0
wandb:               train/train_loss 3.61318
wandb:            train/train_runtime 116.1013
wandb: train/train_samples_per_second 135.313
wandb:   train/train_steps_per_second 2.119
wandb: 
wandb: üöÄ View run stellar-wind-7 at: https://wandb.ai/vbertalan88/huggingface/runs/hqzmgw5t
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230421_132413-hqzmgw5t/logs
