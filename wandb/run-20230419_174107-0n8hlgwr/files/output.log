
  0%|          | 0/63 [00:00<?, ?it/s]You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.

















100%|██████████| 63/63 [00:39<00:00,  1.88it/s]
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|██████████| 63/63 [00:39<00:00,  1.58it/s]
Saving model checkpoint to ./LogFiles
Configuration saved in ./LogFiles/config.json
{'train_runtime': 57.9886, 'train_samples_per_second': 68.979, 'train_steps_per_second': 1.086, 'train_loss': 7.281103224981399, 'epoch': 1.0}
Model weights saved in ./LogFiles/pytorch_model.bin