
  0%|          | 0/32 [00:00<?, ?it/s]You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.







100%|██████████| 32/32 [00:18<00:00,  2.38it/s]
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|██████████| 32/32 [00:18<00:00,  1.69it/s]
Saving model checkpoint to ./Hadoop-Transformer
Configuration saved in ./Hadoop-Transformer/config.json
{'train_runtime': 30.6613, 'train_samples_per_second': 65.229, 'train_steps_per_second': 1.044, 'train_loss': 8.04930591583252, 'epoch': 1.0}
Model weights saved in ./Hadoop-Transformer/pytorch_model.bin